{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awt867ba_PNW",
        "outputId": "715c3d5b-88f1-4ea1-fd1b-294a6fbfea46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install required ***packages***"
      ],
      "metadata": {
        "id": "bXqhVnpeetqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf2\n",
        "!pip install nltk\n",
        "!pip install -U gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETbkASCQ_k3F",
        "outputId": "454e67fc-7cf5-4e96-fddc-1d7b3c5a46d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import necessary libraries"
      ],
      "metadata": {
        "id": "UjbbMrMyec1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api\n",
        "import sklearn\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import PyPDF2"
      ],
      "metadata": {
        "id": "ZGUlDPQvA9t0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2M6x72y6eyyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function to extract text from a PDF file\n",
        "Open the PDF file in binary mode\n",
        "\n",
        "Create a PDF reader object\n",
        "\n",
        "Loop through the pages in the PDF file\n",
        "\n",
        "Get the page object\n",
        "\n",
        "Extract the text from the page"
      ],
      "metadata": {
        "id": "avvHNDNrfF3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "  with open(pdf_path, 'rb') as f:\n",
        "    pdf_reader = PyPDF2.PdfReader(f)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(pdf_reader.pages)):\n",
        "      page = pdf_reader.pages[page_num]\n",
        "      text += page.extract_text()\n",
        "  return text"
      ],
      "metadata": {
        "id": "lPSsNsju_k0O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiH30i_OLopW",
        "outputId": "8819c25a-69c6-41a8-952d-8217c53c1fd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to tokenize sentences from a string\n",
        "Use NLTK's sentence tokenizer to tokenize the text\n",
        "\n",
        "Return the tokenized sentences"
      ],
      "metadata": {
        "id": "Xp_-6__gfnNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentences(text):\n",
        "  tokens = nltk.sent_tokenize(text)\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "do-F9Ilk_kxz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Word2Vec model"
      ],
      "metadata": {
        "id": "vv5SmXZbgK1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v2w_model = None\n",
        "try:\n",
        "  v2w_model = gensim.models.Keyedvectors.load('./w2vecmodel.mod')\n",
        "  print(\"w2v Model Successfully loaded\")\n",
        "except:\n",
        "  v2w_model = api.load('word2vec-google-news-300')\n",
        "  v2w_model.save(\"./w2vecmodel.mod\")\n",
        "  print(\"w2v Model Saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrWHZZ3d_kvs",
        "outputId": "15d10522-7d5f-4411-b4c8-55e4479b13df"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w2v Model Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to get the word embedding of a word"
      ],
      "metadata": {
        "id": "_DcowDhAgf4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_embedding(word, model):\n",
        "  samp = model['pc']\n",
        "  vec = [0]*len(samp)\n",
        "  try:\n",
        "    vec = model[word]\n",
        "  except:\n",
        "    vec = [0]*len(samp)\n",
        "  return vec"
      ],
      "metadata": {
        "id": "oJLbW01x_ktO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to get the phrase embedding of a phrase\n",
        "Initialize a zero vector of the same size as the embedding vectors\n",
        "\n",
        "Initialize a counter for the number of words in the phrase\n",
        "\n",
        "Loop through the words in the phrase\n",
        "\n",
        "Increment the counter\n",
        "\n",
        "Add the word embedding to the phrase embedding\n",
        "\n",
        "Reshape the phrase embedding to a 2D array"
      ],
      "metadata": {
        "id": "CpZI81aJgvkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def get_phrase_embedding(phrase, embeddingmodel):\n",
        "  samp = get_word_embedding('computer', embeddingmodel)\n",
        "  vec = np.array([0]*len(samp))\n",
        "  den = 0;\n",
        "  for word in phrase.split():\n",
        "    den = den+1\n",
        "    vec = vec+np.array(get_word_embedding(word, embeddingmodel))\n",
        "  return vec.reshape(1, -1)"
      ],
      "metadata": {
        "id": "BaTXY5aR_kq6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to retrieve answer to a question from a list of sentences\n",
        "Initialize the maximum similarity score and the index of the most similar sentence\n",
        "\n",
        "Loop through the sentence embeddings\n",
        "\n",
        "Calculate the cosine similarity between the question embedding and the current sentence embedding\n",
        "\n",
        "If the current similarity score is greater than the maximum similarity score, update the maximum\n",
        "similarity score and the index of the most similar sentence\n",
        "\n",
        "Return the index of the most similar sentence"
      ],
      "metadata": {
        "id": "cv45nHpHhNnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_and_print_faq_answer(question_embedding, sentence_embeddings, sentences):\n",
        "  max_sim = -1\n",
        "  index_sim = -1\n",
        "  for index, embedding in enumerate(sentence_embeddings):\n",
        "    sim = cosine_similarity(embedding, question_embedding)[0][0]\n",
        "    if sim > max_sim:\n",
        "      max_sim = sim\n",
        "      index_sim = index\n",
        "\n",
        "  return index_sim"
      ],
      "metadata": {
        "id": "m5M5CALj_koc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main function\n",
        "Extract the text from the PDF file\n",
        "\n",
        "Tokenize the sentences from the text\n",
        "\n",
        "Create a list of sentence embeddings\n",
        "\n",
        "Get the phrase embedding for the question\n",
        "\n",
        "Retrieve and print the answer to the question"
      ],
      "metadata": {
        "id": "GMHBP1nuiT6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(pdf_path, question):\n",
        "\n",
        "  pdf_text = extract_text_from_pdf(pdf_path)\n",
        "  sentences = tokenize_sentences(pdf_text)\n",
        "\n",
        "  sent_embeddings = []\n",
        "  for sent in sentences:\n",
        "    sent_embeddings.append(get_phrase_embedding(sent, v2w_model))\n",
        "\n",
        "  question_embedding = get_phrase_embedding(question, v2w_model)\n",
        "  index = retrieve_and_print_faq_answer(question_embedding, sent_embeddings, sentences)\n",
        "\n",
        "  print(\"Question: \", question)\n",
        "  print(\"Answer: \", sentences[index])"
      ],
      "metadata": {
        "id": "LcdP5kvw_kmI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the main function if the script is run directly\n",
        "Get the path to the PDF file and the question from the user\n",
        "\n",
        "Run the main function"
      ],
      "metadata": {
        "id": "WCkped_2ixMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  pdf_path = input(\"Enter the path to the PDF file: \")\n",
        "  question = input(\"Enter your question: \")\n",
        "  main(pdf_path, question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uYG7fM0_kj3",
        "outputId": "a04248cb-3765-4d36-e053-b4cb4d53a089"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the PDF file: /content/gdrive/MyDrive/Colab Notebooks/acme_terms.pdf\n",
            "Enter your question: what is acme corporation’s approach to handling customer information\n",
            "Question:  what is acme corporation’s approach to handling customer information\n",
            "Answer:  Personal information \n",
            "collected is used solely for improving our services and enhancing user experience.\n"
          ]
        }
      ]
    }
  ]
}